{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/data/com.termux/files/usr/lib/python3.7/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "a = pd.read_csv(\"dictionary/a.txt\", sep=\"  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "to_csv() got an unexpected keyword argument 'delimiter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-09c1bb85c5e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"a_test.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"  \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: to_csv() got an unexpected keyword argument 'delimiter'"
     ]
    }
   ],
   "source": [
    "a.to_csv(\"a_test.txt\", delimiter=str(\"  \"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dictionary/a.txt\", 'r') as fh:\n",
    "    lines = fh.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"a_test.txt\", \"w\") as fh:\n",
    "    fh.write(''.join(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A(det)  AX #@@{ \"usage\": \"unstressed\" }@@\\n',\n",
       " 'A(det)  EY1 #@@{ \"usage\": \"stressed\" }@@\\n',\n",
       " 'A(noun)  EY1\\n',\n",
       " \"A'S  EY1 Z\\n\",\n",
       " 'AABERG: AA1-B-AXR-G\\n',\n",
       " 'AACHEN  AA1 K AX N\\n',\n",
       " 'AACHENER  AA1 K AX N AXR\\n',\n",
       " 'AAH  AA1\\n',\n",
       " 'AAKER  AA1 K AXR\\n',\n",
       " 'AALIYAH  AX L IY1 AX\\n']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('A(det)', 'AX #@@{ \"usage\": \"unstressed\" }@@\\n')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b =lines[0].split(\"  \")\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "det\n"
     ]
    }
   ],
   "source": [
    "word_ver = a.split(\"(\")\n",
    "if len(word_ver) > 1:\n",
    "    ver = word_ver[1][:-1]\n",
    "    print(ver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = [\n",
    "    'a.txt',\n",
    "    'b.txt',\n",
    "    'c.txt',\n",
    "    'd.txt',\n",
    "    'e.txt',\n",
    "    'f.txt',\n",
    "    'g.txt',\n",
    "    'h.txt',\n",
    "    'i.txt',\n",
    "    'j.txt',\n",
    "    'k.txt',\n",
    "    'l.txt',\n",
    "    'm.txt',\n",
    "    'n.txt',\n",
    "    'o.txt',\n",
    "    'p.txt',\n",
    "    'q.txt',\n",
    "    'r.txt',\n",
    "    's.txt',\n",
    "    't.txt',\n",
    "    'u.txt',\n",
    "    'v.txt',\n",
    "    'w.txt',\n",
    "    'x.txt',\n",
    "    'y.txt',\n",
    "    'z.txt',\n",
    "    '{other}.txt',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(fname):\n",
    "    with open(fname, 'r') as fh:\n",
    "        lines = fh.readlines()\n",
    "    new_lines = []\n",
    "\n",
    "    line_to_commit = \"\"\n",
    "    word_to_commit = None\n",
    "    pronun_to_commit = None\n",
    "    set_of_vers = ()\n",
    "\n",
    "    for line in lines:\n",
    "        first, pronun = line.split(\"  \")\n",
    "        word_ver = first.split(\"(\")\n",
    "        if len(word_ver) == 1:\n",
    "            # no multiple versions\n",
    "            # commit previous line:\n",
    "            new_lines.append(line_to_commit)\n",
    "            # put this line up for commit\n",
    "            line_to_commit = line\n",
    "            word_to_commit = first\n",
    "            pronun_to_commit = pronun\n",
    "            continue\n",
    "\n",
    "        word = word_ver[0]\n",
    "        ver = word_ver[1][:-1]\n",
    "        if ver == '2':\n",
    "            # previous line has to be taken into account\n",
    "            new_lines += [word_to_commit + \":\\n\", \"  - \" + pronun_to_commit]\n",
    "            line_to_commit = \"  - \" + pronun\n",
    "        else:\n",
    "            # commit previous line:\n",
    "            new_lines.append(line_to_commit)\n",
    "\n",
    "            if ver in ['3', '4', '5', '6', '7']:\n",
    "                line_to_commit = \"  - \" + pronun\n",
    "            else:\n",
    "                # we have versions with word types\n",
    "                # check if we already had this word:\n",
    "                if word_to_commit != word:\n",
    "                    # this is the first of this word\n",
    "                    new_lines.append(word + \":\\n\")\n",
    "\n",
    "                line_to_commit = f\"  {ver}: {pronun}\"\n",
    "\n",
    "        word_to_commit = word\n",
    "        pronun_to_commit = pronun\n",
    "    return new_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'A:\\n',\n",
       " '  det: AX #@@{ \"usage\": \"unstressed\" }@@\\n',\n",
       " '  det: EY1 #@@{ \"usage\": \"stressed\" }@@\\n',\n",
       " '  noun: EY1\\n',\n",
       " \"A'S  EY1 Z\\n\",\n",
       " 'AABERG  AA1 B AXR G\\n',\n",
       " 'AACHEN  AA1 K AX N\\n',\n",
       " 'AACHENER  AA1 K AX N AXR\\n',\n",
       " 'AAH  AA1\\n']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_lines[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"a_test.txt\", \"w\") as fh:\n",
    "    fh.write(''.join(new_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_duplicates(fname):\n",
    "    with open(fname, 'r') as fh:\n",
    "        lines = fh.readlines()\n",
    "    last_word = \"\"\n",
    "    list_of_vers = []\n",
    "\n",
    "    for line in lines:\n",
    "        first, pronun = line.split(\"  \")\n",
    "        word_ver = first.split(\"(\")\n",
    "        word = first if len(word_ver) == 1 else word_ver[0]\n",
    "\n",
    "        if word != last_word:\n",
    "            # check for duplicates\n",
    "            duplicates = set([x for x in list_of_vers if list_of_vers.count(x) > 1])\n",
    "            if len(duplicates) > 0:\n",
    "                print(last_word, duplicates)\n",
    "\n",
    "        if len(word_ver) == 1:\n",
    "            ver = \"\"\n",
    "        else:\n",
    "            ver = word_ver[1][:-1]\n",
    "\n",
    "        if word == last_word:\n",
    "            list_of_vers.append(ver)\n",
    "            continue\n",
    "\n",
    "        list_of_vers = [ver]\n",
    "        last_word = word\n",
    "#     return new_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RALPH {'noun'}\n",
      "REAL {'noun'}\n",
      "REALS {'noun'}\n",
      "RECOLLECT {'verb'}\n",
      "RECOLLECTED {'verb'}\n",
      "RECOLLECTING {'verb'}\n",
      "RECOLLECTS {'verb'}\n",
      "RECOUNTS {'noun', 'verb'}\n",
      "RECREATION {'noun'}\n",
      "RECREATIONS {'noun'}\n",
      "REDRESS {'noun', 'verb'}\n",
      "REDRESSES {'noun', 'verb'}\n",
      "REDRESSING {'verb'}\n",
      "RESIGN {'verb'}\n",
      "RESIGNED {'verb'}\n",
      "RESIGNING {'verb'}\n",
      "RESIGNS {'verb'}\n",
      "RESOUND {'verb'}\n",
      "RESOUNDED {'verb'}\n",
      "RESOUNDING {'verb'}\n",
      "RETARD {'noun'}\n",
      "RETARDS {'noun'}\n",
      "ROW {'noun', 'verb'}\n",
      "ROWS {'noun', 'verb'}\n",
      "RUGGED {'adj'}\n"
     ]
    }
   ],
   "source": [
    "find_duplicates(\"dictionary/r.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "for letter in filelist:\n",
    "    fname = str(Path(\"dictionary\") / letter)\n",
    "    find_duplicates(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"RECOUNTING\" == \"RECOUNT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "for letter in filelist:\n",
    "    fname = str(Path(\"dictionary\") / letter)\n",
    "    new_lines = convert(fname)\n",
    "    with open(fname, \"w\") as fh:\n",
    "        fh.write(''.join(new_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
